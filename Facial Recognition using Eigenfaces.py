# -*- coding: utf-8 -*-
"""Eigenfaces_LAA_PROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1knuw5N4L3e2s9mCVcKgztDAwrDm6PzOB
"""

import cv2
import os
import numpy as np
import matplotlib.pyplot as plt
from skimage.io import imread
from collections import defaultdict
import statistics
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

"""**Reading the yale dataset**

"""

os.listdir('/content/drive/MyDrive/yalefaces')   #15 classes (distinct people) and 10 images (distinct emotions) per class in training dataset, 1 image per class in test dataset

img_path = "/content/drive/MyDrive/yalefaces"
img_path

# Checking the min and max values of a image
img = imread(os.path.join(img_path,'subject05.wink.jpeg'))
print(np.amin(img),np.amax(img))

# Normalising and plotting one of the sample image
img = imread(os.path.join(img_path,'subject05.wink.jpeg'))/255.0
plt.imshow(img,cmap=plt.cm.gray)

img.shape

np.amin(img),np.amax(img)  #Normalized min and max

test_set = ['subject01.normal.jpeg', 'subject02.normal.jpeg', 'subject03.normal.jpeg', 'subject04.normal.jpeg', 'subject05.normal.jpeg', 'subject06.normal.jpeg', 'subject07.normal.jpeg', 'subject08.normal.jpeg', 'subject09.normal.jpeg', 'subject10.normal.jpeg', 'subject11.normal.jpeg', 'subject12.normal.jpeg', 'subject13.normal.jpeg', 'subject14.normal.jpeg', 'subject15.normal.jpeg']
# for i in range(1,16):
#   if i<10:
#     tag = 'subject0'+str(i)+'.normal'+'.jpeg'
#   else:
#     tag = 'subject' + str(i) +'.normal'+'.jpeg'
#   test_set.append(tag)

# print (test_set)

"""**Finding the Average Image**"""

#Train set images
images = list(os.listdir(img_path))
train_set_images = list(set(images) - set(test_set))
print (len(images),len(train_set_images))

images = train_set_images
images.sort()
print (images)

# Calculating the average image

img = imread(os.path.join(img_path,images[0]))/255.0
print (img.shape)
average_img = np.zeros(img.shape)
#average_img = average_img + img
for file in images[:]:
    img = imread(os.path.join(img_path,file))/255.0
    average_img = average_img + img
n = len(images)
average_img = average_img / n
print (np.amin(average_img),np.amax(average_img))

plt.imshow(average_img,cmap='gray')

"""**Finding deviation**

"""

deviation = []
for img in images:
    image = imread(os.path.join(img_path,img))/255.0
    dev = image - average_img

    deviation.append(dev)

deviation = np.array(deviation)
print (deviation.shape)

fig,axs = plt.subplots(2,3,figsize = (8,6))
for i in range(3):
  axs[0,i].imshow(imread(os.path.join(img_path,images[18*i]))/255.0,cmap = plt.cm.gray)
  axs[1,i].imshow(deviation[18*i,:,:],cmap=plt.cm.gray)
  axs[0,i].set_title("Original")
  axs[1,i].set_title('Deviated')
plt.show()

"""**Calculating the eigen faces**"""

# 77760 = 243 * 320
a = []

for img in deviation:
    flattened = img.flatten()
    
    a.append(flattened)

a = np.array(a) # a[0] -> Column vector phi with dim 77760*1
print(a.shape) # Since numpy treats each column vector(in terms of linalg) as a row, so we take AA^T in the next step instead of A^TA as in the paper.

# L = A^T*A = 150*150 (No. of sample image = 150)
# where, here A = 150 * 77760 and A^T = 77760 * 150
L = a @ a.T
print (L.shape)

eigenvalues, eigenvectors = np.linalg.eigh(L)

print(len(eigenvalues))

print(len(eigenvectors))

sorted_evalues = [(i,j) for i,j in enumerate(eigenvalues)]
print(sorted_evalues)

sorted_evalues.sort(key = lambda sorted_evalues: sorted_evalues[1], reverse = True)
print(sorted_evalues)
# Each eigen vector v_i of (L = A^TA) is 150*1

eigenfaces = []
# each row of this matrix contains eigenface represenation of the deviated images 
# eigenvectors.shape[0]=150
for i in range(150):      # Since there are 150 eigenvectors
  v_l = eigenvectors[i]   # each eigenvector
  u_l = np.zeros(77760)   # u_l=77760x1 
  for j in range(150):
    v_lk = v_l[j]
    u_l = u_l + v_lk * a[j]  #Equation 6 (paper)
  eigenfaces.append(u_l)

eigenfaces = np.array(eigenfaces)
print (eigenfaces.shape)

"""**Top 6 EIGENFACES**

"""

fig,axs = plt.subplots(2,3,figsize = (10,8))
counter = 0
for i in range(2):
  for j in range(3):
    k = sorted_evalues[counter][0]
    counter+=1
    axs[i,j].imshow(eigenfaces[k].reshape(243,320),cmap='gray')
plt.show()

"""**Best K Eigenfaces**"""

# normalising facespace (40 images) for all the vectors of facespace
k = 40
best_k = sorted_evalues[:k]
face_space = []
for i,_ in best_k:
  v = eigenfaces[i]
  v = v/np.linalg.norm(v)
  face_space.append(v)

face_space = np.array(face_space)
print (face_space.shape)

"""**Thresholds - calculation**"""

labels = ['noglasses','happy'] 
# already_tried_labels_combinations 
# labels = ['centerlight','noglasses','happy']
# labels = ['leftlight','noglasses','rightlight','sad']
# labels = ['noglasses','rightlight','sad','sleepy','surprised','wink']
# labels = ['centerlight','glasses','happy','leftlight','noglasses','rightlight','sad','sleepy','surprised','wink']
# To get the characteristics of a class, we take the average of just two images belonging to that class (gives better results).

# For subject 1, the gif and noglasses image is taken and for all the other classes the happy and no glasses images are taken. 
tau = []
for i in range(1,16):
  if i<10:
    tag = 'subject0'+str(i)
  else:
    tag = 'subject' + str(i)

  if tag=='subject01':
    person_1 = tag + '.gif'+".jpeg"
  else:
    person_1 = tag + '.' + labels[0]+".jpeg"
  
  img = imread(os.path.join(img_path,person_1))/255.0
  images___ = np.zeros(img.shape)
  images___ = images___ + img
  for j in range(1,len(labels)):
    person_2 = tag + '.' + labels[j]+".jpeg"    
    image_j = imread(os.path.join(img_path,person_2))/255.0
    images___ = images___ + image_j              # Here, images___ is the sum of the two images of a particular class

  images___ = images___/len(labels)         # Transforming images___ to be the average of the two images
  images___ = images___.flatten()
  tau.append(images___)               

tau = np.array(tau)             # tau is the matrix with average images of each class, where average is calcualated using images of given labels
deviation_for_new_img = tau - (average_img.flatten()) # each row of tau contains the (average of two images of each class)-(average image of the entire set)
print (deviation_for_new_img.shape)                   # (15 x 77760)

# validation set = total 45 images  (for getting the thresholds we use some validation images instead of the entire set of class images)
images_for_threshold_calc = []
# used only these 5 for validation as the paper asked us to use as less of these as possible
image_labels_for_threshold_calc = ['glasses','surprised','sad','sleepy','wink']

for i in range(1,16):                                                           
  if i<10:
    tag = 'subject0'+str(i)
  else:
    tag = 'subject' + str(i)
  for l in image_labels_for_threshold_calc:
    # if l=='centerlight' and tag=='subject01':
    #   images_for_threshold_calc.append(str(tag+'.gif'+".jpeg"))
    # else:                                                     
    images_for_threshold_calc.append(str(tag + '.' + l+'.jpeg'))

print ('The computed threshold from %d (validation) images' %len(images_for_threshold_calc))
face_threshold = 0
epsilons = []
no_of_classes = len(test_set)
counter = 0

epsilonk_thresholds = defaultdict(list)
for index,img in enumerate(images_for_threshold_calc):
  label = int(img.split('.')[0][-2:])
  label = label-1
  
  i = imread(os.path.join(img_path,img))/255.0
  phi = i - average_img       # Deviation for validation set images
  phi = phi.flatten()         # Dim = 1*77760
  omega = face_space @ phi.T  # (40*77760) @ (77760*1) = 40*1    (Equation 7)
  phi_f = np.zeros(face_space[0].shape) # 77760 dim array

  for j in range(face_space.shape[0]):      # face_space.shape[0]=40                     (loop till M' same as what is above euqation 9)
    phi_f = phi_f + omega[j]*face_space[j]  # 77760 array omega[j] is a scalar)          (above equation 9)
  
  for j in range(no_of_classes):             
    omega_j = face_space @ deviation_for_new_img[j].T # 150*1       # omega_j is the projection of the deviation face images of (used 2) per class images using the eigenfaces  
    epsilon_k = np.linalg.norm(omega - omega_j)       
    if label==j: 
      epsilonk_thresholds[label].append(epsilon_k)

# Note: epsilon_k is the distance between the new face class and the original face classes
# Note: Used only 3 images per class to get the epsilon_k thresholds 
# epsilon is the distance between the new face space and the original face space
    

  epsilon = np.linalg.norm(phi - phi_f)
  epsilons.append(epsilon)
  if epsilon > face_threshold:                                    # taking the largest epsilon
    face_threshold = epsilon
    


print (face_threshold)

temp = {}
t = []

for k in epsilonk_thresholds.keys():
  l = epsilonk_thresholds[k]
  m = sum(l)/5
  std = statistics.pstdev(l)
  t.append(m+3*std)
epsilonk_thresholds = t

print (epsilonk_thresholds)

projections = []

def image_test_function(x,test_image,has_face):# Returns an int
  if has_face==False: 
    phi = test_image    
  else:
    phi = test_image - average_img

  phi = phi.flatten()
  omega = face_space @ phi.T
  phi_f = np.zeros(face_space[0].shape)

  for j in range(face_space.shape[0]):
    phi_f = phi_f + omega[j]*face_space[j]

 
  epsilon = np.linalg.norm(phi - phi_f)
 
      #face_threshold= largest epsilon
 
  if (epsilon < face_threshold):
    epsilon_ks = []
    for j in range(len(test_set)):
      omega_j = face_space @ deviation_for_new_img[j].T
      epsilon_k = np.linalg.norm(omega - omega_j)
      epsilon_ks.append(epsilon_k)
     
    possible_classes = []
    minimum_epsilon_k = face_threshold
    minimum_epsilon_k_c = -1
    for k,eps__k in enumerate(epsilon_ks):
      if eps__k < epsilonk_thresholds[k]:
        possible_classes.append(k)
        if eps__k < minimum_epsilon_k:
          minimum_epsilon_k = eps__k
          minimum_epsilon_k_c = k
       

    if possible_classes==[]:
      print (f'Distance from face space i.e. {epsilon} is less than the Face Threshold i.e. {face_threshold}')
      d={"Distance to Classes": epsilon_ks,"Epsilon_k_thresholds":epsilonk_thresholds}
      output=pd.DataFrame(d)
      output['Distance to Classes']=output['Distance to Classes'].round(decimals=2)
      output['Epsilon_k_thresholds']=output['Epsilon_k_thresholds'].round(decimals=2)
      print ('Unknown Image')
     
      fig, ax = plt.subplots()
      ax.axis('off')
      ax.table(cellText=output.values, colLabels=output.columns, loc='center')
      fig.tight_layout()
      fig.set_size_inches(4, 10)
      plt.show()
      return (int(100))
    else:
      print (f'Distance from face space i.e. {epsilon} is less than the Face Threshold i.e. {face_threshold}')
      # print ('Face Threshold=%f' %face_threshold)
      # print ('Possible classes for the face that it was compared to before prediction:')
      # print (c)
      print ('Predicted Class = %s' %(minimum_epsilon_k_c))
      print ('Original class Label = %d' %x)
      x=[]
      for i in range(0,15):
        if i in possible_classes:
          x.append('Possible')
        else:
          x.append('Not Possible')
      d={"Distance to Classes": epsilon_ks,"Epsilon_k_thresholds":epsilonk_thresholds,'Is it a possible class':x}
      output=pd.DataFrame(d)
      
      output['Distance to Classes']=output['Distance to Classes'].round(decimals=2)
      output['Epsilon_k_thresholds']=output['Epsilon_k_thresholds'].round(decimals=2)
      fig, ax = plt.subplots()
      ax.axis('off')
      ax.table(cellText=output.values, colLabels=output.columns, loc='center')
      fig.tight_layout()
      fig.set_size_inches(8, 10)
      plt.show()
      return (minimum_epsilon_k_c)
  else:
    print (f'Distance from face space i.e. {epsilon} is greater than the Face Threshold i.e. {face_threshold}')
    print ('It is not a Human Face')
    return (int(-1))

"""**Testing the known face images**"""

counter = 0
for i in range(len(test_set)):
  test_image = imread(os.path.join("/content/drive/MyDrive/test_data_all_normal",test_set[i]))/255.0
  original_class_label = i
  predicted_label = image_test_function(i,test_image,has_face = True)
  if original_class_label == predicted_label:
    counter +=1

print ("No. of correct classifications: %d out of %d test set images " %(counter,len(test_set)))

"""**Displaying not from dataset image**"""

i = imread(os.path.join(img_path,'/content/drive/MyDrive/resize_done/subject01.notface.jpeg'))/255.0
plt.title("Non-face image")
plt.imshow(i,cmap=plt.cm.gray)

i = imread(os.path.join(img_path,'/content/drive/MyDrive/resize_done/subject02.notface.jpeg'))/255.0
plt.title("Non-face image")
plt.imshow(i,cmap=plt.cm.gray)

i = imread(os.path.join(img_path,'/content/drive/MyDrive/resize_done_facenew/subject01.face.jpeg'))/255.0
plt.title("Not a known image")
plt.imshow(i,cmap=plt.cm.gray)

"""**Testing the non face images**"""

test_set_nonfaceimg = ['subject01.notface.jpeg', 'subject02.notface.jpeg']

counter = 0
for i in range(len(test_set_nonfaceimg)):
  test_image = imread(os.path.join("/content/drive/MyDrive/resize_done",test_set_nonfaceimg[i]))/255.0
  predicted_label = image_test_function(i,test_image,has_face=False)
  if original_class_label == predicted_label:
    counter +=1

"""**Testing a face image not from the dataset**"""

img = 'subject0'+str(1)+'.face'+'.jpeg'
test_image = imread(os.path.join("/content/drive/MyDrive/resize_done_facenew",img))/255.0
predicted_label = image_test_function(None,test_image,has_face=True)